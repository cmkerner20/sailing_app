{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When MLData104.csv is removed. Train:  0.9995 Inner Test: 0.8982 Outer Test 0.8545\n",
      "When MLData106.csv is removed. Train:  0.9993 Inner Test: 0.8988 Outer Test 0.7868\n",
      "When MLData117.csv is removed. Train:  0.9992 Inner Test: 0.9006 Outer Test 0.8172\n",
      "When /MLData90.csv is removed. Train:  0.9993 Inner Test: 0.9033 Outer Test 0.6951\n",
      "When /MLData91.csv is removed. Train:  0.9988 Inner Test: 0.8997 Outer Test 0.5625\n",
      "When /MLData85.csv is removed. Train:  0.9989 Inner Test: 0.9001 Outer Test 0.1615\n",
      "When LData_153.csv is removed. Train:  0.9989 Inner Test: 0.8921 Outer Test 0.9308\n",
      "When /MLData87.csv is removed. Train:  0.9994 Inner Test: 0.9066 Outer Test 0.5853\n",
      "When /MLData86.csv is removed. Train:  0.9994 Inner Test: 0.9046 Outer Test 0.3361\n",
      "When MLData153.csv is removed. Train:  0.9989 Inner Test: 0.8902 Outer Test 0.9269\n",
      "When /MLData75.csv is removed. Train:  0.9991 Inner Test: 0.9036 Outer Test 0.6163\n",
      "When /MLData88.csv is removed. Train:  0.9992 Inner Test: 0.8994 Outer Test 0.5264\n",
      "When /MLData76.csv is removed. Train:  0.999 Inner Test: 0.9011 Outer Test 0.6537\n",
      "When /MLData89.csv is removed. Train:  0.999 Inner Test: 0.9048 Outer Test 0.5841\n",
      "When MLData124.csv is removed. Train:  0.9993 Inner Test: 0.9023 Outer Test 0.66\n",
      "When MLData118.csv is removed. Train:  0.9992 Inner Test: 0.9 Outer Test 0.7726\n",
      "When MLData133.csv is removed. Train:  0.9993 Inner Test: 0.9007 Outer Test 0.785\n",
      "When MLData132.csv is removed. Train:  0.9992 Inner Test: 0.9018 Outer Test 0.8369\n",
      "When MLData122.csv is removed. Train:  0.9995 Inner Test: 0.9006 Outer Test 0.8165\n",
      "When MLData123.csv is removed. Train:  0.9989 Inner Test: 0.8994 Outer Test 0.8387\n",
      "When MLData109.csv is removed. Train:  0.9991 Inner Test: 0.8975 Outer Test 0.8228\n",
      "When MLData121.csv is removed. Train:  0.9991 Inner Test: 0.9026 Outer Test 0.6319\n",
      "When MLData134.csv is removed. Train:  0.9992 Inner Test: 0.8993 Outer Test 0.8003\n",
      "When MLData120.csv is removed. Train:  0.9993 Inner Test: 0.9012 Outer Test 0.7254\n"
     ]
    }
   ],
   "source": [
    "path= '/Users/tancredicp/Desktop/sailing_app/data/ML Training Resources/'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "for i in range(24):\n",
    "    \n",
    "    listOfNormalizedDatFrames = []\n",
    "    listofTags = []\n",
    "\n",
    "    listOfNormalizedDatFramesTest = []\n",
    "    listofTagsTest = []\n",
    "    for counter, filename in enumerate(all_files):\n",
    "            \n",
    "            \n",
    "        dfSpecific = pd.read_csv(filename, index_col=None, header=0)\n",
    "\n",
    "        #I was lazy and did not check where the NaNs where but they were being annoying so made them all 0s.\n",
    "        dfSpecific.fillna(0, inplace= True)\n",
    "\n",
    "        dfSpecificY = dfSpecific[['tag']]\n",
    "        dfSpecificY = dfSpecificY['tag'].astype('category')\n",
    "    #     dfSpecificY = dfSpecificY['tag'].map({'0': 0, 'S': 1, 'C': 2, 'G': 3, 'T': 4, 'B':5,'D': 6 })\n",
    "        \n",
    "\n",
    "        dfSpecificX = dfSpecific.drop(columns=['tag', 'tag_name', 'boat_class', 'time'])\n",
    "\n",
    "        #standardize data\n",
    "        scaler = StandardScaler()\n",
    "        columnsBeingStandardize = ['lat', 'lon', 'sog', 'heel', 'clew_load','pitch']\n",
    "        dfSpecificX[columnsBeingStandardize] = scaler.fit_transform(dfSpecificX[columnsBeingStandardize])\n",
    "        \n",
    "        if i == counter:\n",
    "            listOfNormalizedDatFramesTest.append(dfSpecificX)\n",
    "            listofTagsTest.append(dfSpecificY)\n",
    "        else:\n",
    "            listofTags.append(dfSpecificY)\n",
    "            listOfNormalizedDatFrames.append(dfSpecificX)\n",
    "\n",
    "    X = pd.concat(listOfNormalizedDatFrames, axis=0, ignore_index=True)\n",
    "    y = pd.concat(listofTags, axis=0, ignore_index=True)\n",
    "    \n",
    "    X2 = pd.concat(listOfNormalizedDatFramesTest, axis=0, ignore_index=True)\n",
    "    y2 = pd.concat(listofTagsTest, axis=0, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 3, test_size = 0.8)\n",
    "    RFC = RandomForestClassifier(n_estimators= 25)\n",
    "    RFC.fit(X_train,y_train)\n",
    "    print(\"When \" + all_files[i][-13:] + \" is removed.\", \"Train: \", np.round(RFC.score(X_train, y_train),4), \"Inner Test:\" ,  np.round(RFC.score(X_test, y_test),4), \"Outer Test\", np.round(RFC.score(X2, y2),4))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
