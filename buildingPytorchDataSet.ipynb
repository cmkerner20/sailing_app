{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building the iterator is almost as hard as building the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = data.Field(unk_token = None)\n",
    "TAGS.build_vocab(['0','S', 'C','G','T','B','D', 'A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAGS.numericalize(['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5169, -0.5162,  1.3716, -0.3000],\n",
      "        [ 0.5262, -0.5372,  1.5119, -0.3111],\n",
      "        [ 0.5362, -0.5570,  1.4558, -0.2722],\n",
      "        ...,\n",
      "        [ 0.9956, -1.3453, -1.1912, -0.3667],\n",
      "        [ 0.9956, -1.3475, -1.1459, -0.4167],\n",
      "        [ 0.9958, -1.3498, -1.1697, -0.4389]], dtype=torch.float64)\n",
      "tensor([[ 1.0801, -0.8038, -1.6933,  0.3556],\n",
      "        [ 1.1136, -0.7263, -1.6693,  0.2056],\n",
      "        [ 1.0522, -0.3454,  0.1338,  0.6667],\n",
      "        ...,\n",
      "        [ 0.8140, -1.7687, -1.7196, -0.4778],\n",
      "        [ 0.8146, -1.7702, -1.5906, -0.3167],\n",
      "        [ 0.8147, -1.7718, -1.6453, -0.4111]], dtype=torch.float64)\n",
      "tensor([[ 0.9253, -0.1155, -1.2771,  0.3389],\n",
      "        [ 0.9258, -0.1135, -1.2578,  0.3667],\n",
      "        [ 0.9263, -0.1116, -1.2578,  0.3333],\n",
      "        ...,\n",
      "        [ 0.9826, -1.1953,  0.4812, -0.7722],\n",
      "        [ 0.9764, -1.2083,  0.5179, -0.7556],\n",
      "        [ 0.9702, -1.2210,  0.4602, -0.7611]], dtype=torch.float64)\n",
      "tensor([[ 1.3487,  0.7451,  0.1557,  0.8389],\n",
      "        [ 1.3186,  0.7565,  0.3055,  0.9444],\n",
      "        [ 1.2815,  0.7648,  0.3055,  0.9333],\n",
      "        ...,\n",
      "        [ 0.2183,  0.1994, -0.0583, -0.2500],\n",
      "        [ 0.2368,  0.1807, -0.0583, -0.2778],\n",
      "        [ 0.2600,  0.1589,  0.0059, -0.2389]], dtype=torch.float64)\n",
      "tensor([[ 0.4958,  0.5608, -1.2672, -0.2611],\n",
      "        [ 0.4958,  0.5608, -1.2672, -0.2611],\n",
      "        [ 0.4958,  0.5608, -1.2672, -0.2611],\n",
      "        ...,\n",
      "        [ 0.6634,  0.7911,  0.3799,  0.7944],\n",
      "        [ 0.6029,  0.8012,  0.2255,  0.9500],\n",
      "        [ 0.5423,  0.8012,  0.0711,  0.9667]], dtype=torch.float64)\n",
      "tensor([[-0.9637,  0.4328, -0.6352,  0.8111],\n",
      "        [-0.9644,  0.4334, -0.6671,  0.7333],\n",
      "        [-0.9647,  0.4341, -0.6671,  0.7333],\n",
      "        ...,\n",
      "        [ 0.2086, -0.8959, -0.5332, -0.3889],\n",
      "        [ 0.2090, -0.8975, -0.5332, -0.3889],\n",
      "        [ 0.2097, -0.8989, -0.5109, -0.3722]], dtype=torch.float64)\n",
      "tensor([[ 2.0178,  1.5176, -1.3845,  0.0000],\n",
      "        [ 2.0151,  1.5176, -0.5638,  0.9389],\n",
      "        [ 2.0133,  1.5180, -0.7919, -0.9889],\n",
      "        ...,\n",
      "        [ 1.9931,  1.5058, -1.2258, -0.8722],\n",
      "        [ 1.9920,  1.5057, -1.0646, -0.8333],\n",
      "        [ 1.9904,  1.5053, -1.3845, -0.8333]], dtype=torch.float64)\n",
      "tensor([[-1.9246, -0.0258,  0.4290, -0.2778],\n",
      "        [-1.9197, -0.0286,  0.4762, -0.2889],\n",
      "        [-1.9150, -0.0315,  0.4997, -0.2889],\n",
      "        ...,\n",
      "        [ 0.6302,  0.7313,  0.7121, -0.0111],\n",
      "        [ 0.6386,  0.7310,  0.8064, -0.0167],\n",
      "        [ 0.6473,  0.7308,  0.8536, -0.0167]], dtype=torch.float64)\n",
      "tensor([[-14.2420,  -3.7189,   0.1490,   0.0500],\n",
      "        [-12.8699,  -3.4448,   3.3412,   0.1944],\n",
      "        [-10.6973,  -3.1396,   2.9757,   0.0611],\n",
      "        ...,\n",
      "        [  0.6134,   1.4822,  -1.6638,  -0.1389],\n",
      "        [  0.6154,   1.4818,  -1.5743,  -0.1722],\n",
      "        [  0.6173,   1.4814,  -1.6638,  -0.1500]], dtype=torch.float64)\n",
      "tensor([[ 2.0178,  1.5176, -1.3845,  0.0000],\n",
      "        [ 2.0151,  1.5176, -0.5638,  0.9389],\n",
      "        [ 2.0133,  1.5180, -0.7919, -0.9889],\n",
      "        ...,\n",
      "        [ 1.9931,  1.5058, -1.2258, -0.8722],\n",
      "        [ 1.9920,  1.5057, -1.0646, -0.8333],\n",
      "        [ 1.9904,  1.5053, -1.3845, -0.8333]], dtype=torch.float64)\n",
      "tensor([[ 1.3373,  0.9395, -0.4344, -0.6222],\n",
      "        [ 1.2317,  0.4778, -1.9801, -0.6222],\n",
      "        [ 1.2194,  0.4224, -1.2892, -0.7889],\n",
      "        ...,\n",
      "        [ 1.2364, -0.5683, -1.9064, -0.2389],\n",
      "        [ 1.2377, -0.5699, -1.9064, -0.2056],\n",
      "        [ 1.2383, -0.5710, -1.9392, -0.2056]], dtype=torch.float64)\n",
      "tensor([[ 0.7602,  0.9812,  0.1936,  0.9611],\n",
      "        [ 0.7362,  0.9901,  0.1936,  0.9278],\n",
      "        [ 0.7084,  1.0123,  0.3493,  0.8889],\n",
      "        ...,\n",
      "        [-0.0938, -1.6130, -0.8963,  0.9389],\n",
      "        [-0.0938, -1.6130, -0.8963,  0.9389],\n",
      "        [-0.0938, -1.6130, -0.8963,  0.9389]], dtype=torch.float64)\n",
      "tensor([[ 1.1552, -1.5920, -1.8542, -0.2833],\n",
      "        [ 1.1557, -1.5927, -1.9157, -0.2667],\n",
      "        [ 1.1557, -1.5937, -1.9157, -0.3278],\n",
      "        ...,\n",
      "        [ 0.4155, -2.2816, -0.3947, -0.7944],\n",
      "        [ 0.4101, -2.2891, -0.3385, -0.8167],\n",
      "        [ 0.4046, -2.2963, -0.2528, -0.8111]], dtype=torch.float64)\n",
      "tensor([[ 0.6853,  0.7108, -1.0699, -0.8167],\n",
      "        [ 0.6814,  0.7025, -1.0699, -0.6333],\n",
      "        [ 0.6776,  0.6970, -1.0699, -0.6333],\n",
      "        ...,\n",
      "        [-0.3806, -0.1967, -0.6744, -0.7778],\n",
      "        [-0.3863, -0.2022, -0.6744, -0.7833],\n",
      "        [-0.3902, -0.2105, -1.0699, -0.8333]], dtype=torch.float64)\n",
      "tensor([[-0.7924, -0.8621,  0.1067,  0.8889],\n",
      "        [-0.8093, -0.8600, -0.0073,  0.9000],\n",
      "        [-0.8262, -0.8578,  0.0532,  0.8889],\n",
      "        ...,\n",
      "        [ 0.1233, -0.8289, -1.1012,  0.1611],\n",
      "        [ 0.1271, -0.8284, -1.1897,  0.1111],\n",
      "        [ 0.1304, -0.8277, -1.1268,  0.1444]], dtype=torch.float64)\n",
      "tensor([[ 1.0243, -0.8596, -1.1631,  0.6778],\n",
      "        [ 1.0230, -0.8561, -1.1412,  0.6889],\n",
      "        [ 1.0218, -0.8532, -1.2945,  0.7000],\n",
      "        ...,\n",
      "        [-0.6477, -3.7568,  1.3201, -0.4722],\n",
      "        [-0.6454, -3.7797,  1.3201, -0.4389],\n",
      "        [-0.6416, -3.8026,  1.3401, -0.4111]], dtype=torch.float64)\n",
      "tensor([[-0.9511, -0.8282, -1.2322, -0.0222],\n",
      "        [-0.9476, -0.8276, -1.2727,  0.0389],\n",
      "        [-0.9422, -0.8269, -1.0917,  0.0944],\n",
      "        ...,\n",
      "        [ 1.4298, -0.8021, -0.9630,  0.0389],\n",
      "        [ 1.4381, -0.8019, -0.9130,  0.0222],\n",
      "        [ 1.4470, -0.8015, -0.7963,  0.0333]], dtype=torch.float64)\n",
      "tensor([[-0.6061, -0.8358, -1.3212,  0.1333],\n",
      "        [-0.6026, -0.8353, -1.3839,  0.0833],\n",
      "        [-0.5976, -0.8353, -1.2613,  0.0833],\n",
      "        ...,\n",
      "        [-0.0672, -0.8618, -0.4847,  0.0056],\n",
      "        [-0.0568, -0.8635, -0.0732, -0.0833],\n",
      "        [-0.0441, -0.8668,  0.3710, -0.1278]], dtype=torch.float64)\n",
      "tensor([[-0.5720, -1.0452, -1.4961,  0.2000],\n",
      "        [-0.5706, -1.0450, -1.5486,  0.2056],\n",
      "        [-0.5683, -1.0448, -1.4536,  0.1056],\n",
      "        ...,\n",
      "        [ 1.5779, -0.8246, -0.4404, -0.7889],\n",
      "        [ 1.5689, -0.8262, -0.6706, -0.8667],\n",
      "        [ 1.5598, -0.8275, -0.6281, -0.8889]], dtype=torch.float64)\n",
      "tensor([[-1.0926, -0.8198, -1.3686,  0.0611],\n",
      "        [-1.0902, -0.8200, -1.2803,  0.0500],\n",
      "        [-1.0887, -0.8204, -1.3065, -0.0556],\n",
      "        ...,\n",
      "        [-0.0886, -0.8043,  0.4103, -0.3500],\n",
      "        [-0.0871, -0.8112,  0.2168, -0.4833],\n",
      "        [-0.0905, -0.8165, -0.2106, -0.6000]], dtype=torch.float64)\n",
      "tensor([[ 0.8135, -0.4073, -1.3929,  0.3278],\n",
      "        [ 0.8372, -0.2623, -1.4147,  0.3056],\n",
      "        [ 0.8610, -0.1204, -1.2842,  0.4000],\n",
      "        ...,\n",
      "        [ 1.1008, -0.2343, -1.4661,  0.1389],\n",
      "        [ 1.1013, -0.2339, -1.4661,  0.1444],\n",
      "        [ 1.1018, -0.2328, -1.4443,  0.1722]], dtype=torch.float64)\n",
      "tensor([[-0.5045, -0.8959, -1.3336,  0.0722],\n",
      "        [-0.5024, -0.8956, -1.4420,  0.0722],\n",
      "        [-0.5003, -0.8950, -1.3052,  0.1389],\n",
      "        ...,\n",
      "        [-1.2056, -0.8004,  0.4938, -0.2611],\n",
      "        [-1.1955, -0.8070,  0.6435, -0.3000],\n",
      "        [-1.1841, -0.8137,  0.7700, -0.2833]], dtype=torch.float64)\n",
      "tensor([[ 0.1226, -1.0013, -0.9876,  0.1667],\n",
      "        [ 0.1252, -1.0003, -1.3328,  0.1556],\n",
      "        [ 0.1278, -0.9991, -1.2969,  0.1611],\n",
      "        ...,\n",
      "        [-0.1849, -0.8772,  0.3713, -0.2889],\n",
      "        [-0.1790, -0.8839,  0.5066, -0.3000],\n",
      "        [-0.1723, -0.8904,  0.5342, -0.2778]], dtype=torch.float64)\n",
      "tensor([[ 0.3790, -0.5101, -1.7803,  0.0389],\n",
      "        [-0.1900,  0.8822,  0.1684,  0.1611],\n",
      "        [-0.1718,  0.8871,  0.2485,  0.1833],\n",
      "        ...,\n",
      "        [-0.9690, -1.6392, -2.0836, -0.7111],\n",
      "        [-0.9687, -1.6394, -2.0836, -0.7111],\n",
      "        [-0.9684, -1.6396, -2.0836, -0.7111]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "path= '/Users/tancredicp/Desktop/sailing_app/data/ML Training Resources/'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "# listOfNormalizedDatFrames = []\n",
    "# listofTags = []\n",
    "\n",
    "Data = []\n",
    "\n",
    "counter = -1\n",
    "\n",
    "for filename in all_files:\n",
    "    temporary_dict = {}\n",
    "\n",
    "    \n",
    "    \n",
    "    dfSpecific = pd.read_csv(filename, index_col=None, header=0)\n",
    "#     print(dfSpecific.shape)\n",
    "    #I was lazy and did not check where the NaNs where but they were being annoying so made them all 0s.\n",
    "    dfSpecific.fillna(0, inplace= True)\n",
    "    \n",
    "    dfSpecificY = dfSpecific[['tag']]\n",
    "    dfSpecificY = dfSpecificY['tag'] #.astype('category')\n",
    "    \n",
    "    \n",
    "    temporary_dict['tags'] = TAGS.numericalize((np.array(dfSpecificY)))\n",
    "    \n",
    "\n",
    "    \n",
    "    dfSpecificX = dfSpecific.drop(columns=['tag', 'tag_name', 'boat_class', 'time'])\n",
    "    scaler = StandardScaler()\n",
    "    columnsBeingStandardize = ['lat', 'lon', 'sog', 'heel', 'clew_load','pitch']\n",
    "    dfSpecificX[columnsBeingStandardize] = scaler.fit_transform(dfSpecificX[columnsBeingStandardize])\n",
    "    \n",
    "    \n",
    "    array1 = np.array(dfSpecificX[['lat', 'lon', 'sog', 'cog']])\n",
    "    \n",
    "    print(torch.from_numpy(array1).type(torch.DoubleTensor))\n",
    "    \n",
    "    temporary_dict['track'] = torch.from_numpy(array1).type(torch.DoubleTensor)\n",
    "#     print(temporary_dict)\n",
    "    \n",
    "    Data.append(temporary_dict)\n",
    "    \n",
    "#     listOfNormalizedDatFrames[counter] = array1\n",
    "    \n",
    "#     break\n",
    "\n",
    "# X = pd.concat(listOfNormalizedDatFrames, axis=0, ignore_index=True)\n",
    "# y = pd.concat(listofTags, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SailingData(Dataset):\n",
    "    def __init__ (self, pl):\n",
    "        self.samples = []\n",
    "        \n",
    "        for d in pl:\n",
    "            self.samples.append((d['track'], d['tags']))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "            return(self.samples[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "Dataset1= SailingData(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5169, -0.5162,  1.3716, -0.3000],\n",
       "         [ 0.5262, -0.5372,  1.5119, -0.3111],\n",
       "         [ 0.5362, -0.5570,  1.4558, -0.2722],\n",
       "         ...,\n",
       "         [ 0.9956, -1.3453, -1.1912, -0.3667],\n",
       "         [ 0.9956, -1.3475, -1.1459, -0.4167],\n",
       "         [ 0.9958, -1.3498, -1.1697, -0.4389]], dtype=torch.float64),\n",
       " tensor([[7, 7, 7,  ..., 4, 4, 4]]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(Dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x130a8c8d0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers = n_layers, \n",
    "                            bidirectional = bidirectional)\n",
    "                           # dropout = dropout if n_layers > 0.9 else 0.1)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "       \n",
    "        print(\"inside\", text)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.lstm(text)\n",
    " \n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        \n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 4\n",
    "HIDDEN_DIM = 32\n",
    "OUTPUT_DIM = len(TAGS.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = False\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = BiLSTMPOSTagger(INPUT_DIM,  \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMPOSTagger(\n",
       "  (lstm): LSTM(4, 32, num_layers=2)\n",
       "  (fc): Linear(in_features=32, out_features=9, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,609 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    print(iterator)\n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch[0]\n",
    "        tags = batch[1]\n",
    "        \n",
    "        \n",
    "        print('text', text)\n",
    "        print('tag', tags)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        predictions = model(text)\n",
    "        \n",
    " \n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "\n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = categorical_accuracy(predictions, tags)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x130a8c8d0>\n",
      "text tensor([[[ 0.5169, -0.5162,  1.3716, -0.3000],\n",
      "         [ 0.5262, -0.5372,  1.5119, -0.3111],\n",
      "         [ 0.5362, -0.5570,  1.4558, -0.2722],\n",
      "         ...,\n",
      "         [ 0.9956, -1.3453, -1.1912, -0.3667],\n",
      "         [ 0.9956, -1.3475, -1.1459, -0.4167],\n",
      "         [ 0.9958, -1.3498, -1.1697, -0.4389]]], dtype=torch.float64)\n",
      "tag tensor([[[7, 7, 7,  ..., 4, 4, 4]]])\n",
      "inside tensor([[[ 0.5169, -0.5162,  1.3716, -0.3000],\n",
      "         [ 0.5262, -0.5372,  1.5119, -0.3111],\n",
      "         [ 0.5362, -0.5570,  1.4558, -0.2722],\n",
      "         ...,\n",
      "         [ 0.9956, -1.3453, -1.1912, -0.3667],\n",
      "         [ 0.9956, -1.3475, -1.1459, -0.4167],\n",
      "         [ 0.9958, -1.3498, -1.1697, -0.4389]]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-896c87261664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-221-7e3c81133af7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sailing_env/sailing/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-215-121249bb9e67>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inside\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sailing_env/sailing/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sailing_env/sailing/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 570\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.5169, -0.5162,  1.3716, -0.3000],\n",
      "         [ 0.5262, -0.5372,  1.5119, -0.3111],\n",
      "         [ 0.5362, -0.5570,  1.4558, -0.2722],\n",
      "         ...,\n",
      "         [ 0.9956, -1.3453, -1.1912, -0.3667],\n",
      "         [ 0.9956, -1.3475, -1.1459, -0.4167],\n",
      "         [ 0.9958, -1.3498, -1.1697, -0.4389]]], dtype=torch.float64), tensor([[[7, 7, 7,  ..., 4, 4, 4]]])]\n",
      "[tensor([[[ 1.0801, -0.8038, -1.6933,  0.3556],\n",
      "         [ 1.1136, -0.7263, -1.6693,  0.2056],\n",
      "         [ 1.0522, -0.3454,  0.1338,  0.6667],\n",
      "         ...,\n",
      "         [ 0.8140, -1.7687, -1.7196, -0.4778],\n",
      "         [ 0.8146, -1.7702, -1.5906, -0.3167],\n",
      "         [ 0.8147, -1.7718, -1.6453, -0.4111]]], dtype=torch.float64), tensor([[[2, 2, 2,  ..., 4, 4, 4]]])]\n",
      "[tensor([[[ 0.9253, -0.1155, -1.2771,  0.3389],\n",
      "         [ 0.9258, -0.1135, -1.2578,  0.3667],\n",
      "         [ 0.9263, -0.1116, -1.2578,  0.3333],\n",
      "         ...,\n",
      "         [ 0.9826, -1.1953,  0.4812, -0.7722],\n",
      "         [ 0.9764, -1.2083,  0.5179, -0.7556],\n",
      "         [ 0.9702, -1.2210,  0.4602, -0.7611]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 4, 4, 4]]])]\n",
      "[tensor([[[ 1.3487,  0.7451,  0.1557,  0.8389],\n",
      "         [ 1.3186,  0.7565,  0.3055,  0.9444],\n",
      "         [ 1.2815,  0.7648,  0.3055,  0.9333],\n",
      "         ...,\n",
      "         [ 0.2183,  0.1994, -0.0583, -0.2500],\n",
      "         [ 0.2368,  0.1807, -0.0583, -0.2778],\n",
      "         [ 0.2600,  0.1589,  0.0059, -0.2389]]], dtype=torch.float64), tensor([[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "          8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "          3, 3, 3, 3, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,\n",
      "          6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6,\n",
      "          6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "          5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
      "          8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]])]\n",
      "[tensor([[[ 0.4958,  0.5608, -1.2672, -0.2611],\n",
      "         [ 0.4958,  0.5608, -1.2672, -0.2611],\n",
      "         [ 0.4958,  0.5608, -1.2672, -0.2611],\n",
      "         ...,\n",
      "         [ 0.6634,  0.7911,  0.3799,  0.7944],\n",
      "         [ 0.6029,  0.8012,  0.2255,  0.9500],\n",
      "         [ 0.5423,  0.8012,  0.0711,  0.9667]]], dtype=torch.float64), tensor([[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 7, 7, 7, 7, 7, 7, 7,\n",
      "          7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 7, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 7, 7, 7, 7, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 3, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 1, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "          7, 7, 7, 7, 7, 7, 7, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "          6, 1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])]\n",
      "[tensor([[[-0.9637,  0.4328, -0.6352,  0.8111],\n",
      "         [-0.9644,  0.4334, -0.6671,  0.7333],\n",
      "         [-0.9647,  0.4341, -0.6671,  0.7333],\n",
      "         ...,\n",
      "         [ 0.2086, -0.8959, -0.5332, -0.3889],\n",
      "         [ 0.2090, -0.8975, -0.5332, -0.3889],\n",
      "         [ 0.2097, -0.8989, -0.5109, -0.3722]]], dtype=torch.float64), tensor([[[1, 4, 4,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[ 2.0178,  1.5176, -1.3845,  0.0000],\n",
      "         [ 2.0151,  1.5176, -0.5638,  0.9389],\n",
      "         [ 2.0133,  1.5180, -0.7919, -0.9889],\n",
      "         ...,\n",
      "         [ 1.9931,  1.5058, -1.2258, -0.8722],\n",
      "         [ 1.9920,  1.5057, -1.0646, -0.8333],\n",
      "         [ 1.9904,  1.5053, -1.3845, -0.8333]]], dtype=torch.float64), tensor([[[1, 1, 1,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[-1.9246, -0.0258,  0.4290, -0.2778],\n",
      "         [-1.9197, -0.0286,  0.4762, -0.2889],\n",
      "         [-1.9150, -0.0315,  0.4997, -0.2889],\n",
      "         ...,\n",
      "         [ 0.6302,  0.7313,  0.7121, -0.0111],\n",
      "         [ 0.6386,  0.7310,  0.8064, -0.0167],\n",
      "         [ 0.6473,  0.7308,  0.8536, -0.0167]]], dtype=torch.float64), tensor([[[7, 7, 7,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[-14.2420,  -3.7189,   0.1490,   0.0500],\n",
      "         [-12.8699,  -3.4448,   3.3412,   0.1944],\n",
      "         [-10.6973,  -3.1396,   2.9757,   0.0611],\n",
      "         ...,\n",
      "         [  0.6134,   1.4822,  -1.6638,  -0.1389],\n",
      "         [  0.6154,   1.4818,  -1.5743,  -0.1722],\n",
      "         [  0.6173,   1.4814,  -1.6638,  -0.1500]]], dtype=torch.float64), tensor([[[1, 1, 1,  ..., 4, 4, 4]]])]\n",
      "[tensor([[[ 2.0178,  1.5176, -1.3845,  0.0000],\n",
      "         [ 2.0151,  1.5176, -0.5638,  0.9389],\n",
      "         [ 2.0133,  1.5180, -0.7919, -0.9889],\n",
      "         ...,\n",
      "         [ 1.9931,  1.5058, -1.2258, -0.8722],\n",
      "         [ 1.9920,  1.5057, -1.0646, -0.8333],\n",
      "         [ 1.9904,  1.5053, -1.3845, -0.8333]]], dtype=torch.float64), tensor([[[1, 1, 1,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[ 1.3373,  0.9395, -0.4344, -0.6222],\n",
      "         [ 1.2317,  0.4778, -1.9801, -0.6222],\n",
      "         [ 1.2194,  0.4224, -1.2892, -0.7889],\n",
      "         ...,\n",
      "         [ 1.2364, -0.5683, -1.9064, -0.2389],\n",
      "         [ 1.2377, -0.5699, -1.9064, -0.2056],\n",
      "         [ 1.2383, -0.5710, -1.9392, -0.2056]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 4, 1, 1]]])]\n",
      "[tensor([[[ 0.7602,  0.9812,  0.1936,  0.9611],\n",
      "         [ 0.7362,  0.9901,  0.1936,  0.9278],\n",
      "         [ 0.7084,  1.0123,  0.3493,  0.8889],\n",
      "         ...,\n",
      "         [-0.0938, -1.6130, -0.8963,  0.9389],\n",
      "         [-0.0938, -1.6130, -0.8963,  0.9389],\n",
      "         [-0.0938, -1.6130, -0.8963,  0.9389]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[ 1.1552, -1.5920, -1.8542, -0.2833],\n",
      "         [ 1.1557, -1.5927, -1.9157, -0.2667],\n",
      "         [ 1.1557, -1.5937, -1.9157, -0.3278],\n",
      "         ...,\n",
      "         [ 0.4155, -2.2816, -0.3947, -0.7944],\n",
      "         [ 0.4101, -2.2891, -0.3385, -0.8167],\n",
      "         [ 0.4046, -2.2963, -0.2528, -0.8111]]], dtype=torch.float64), tensor([[[1, 1, 1,  ..., 4, 1, 1]]])]\n",
      "[tensor([[[ 0.6853,  0.7108, -1.0699, -0.8167],\n",
      "         [ 0.6814,  0.7025, -1.0699, -0.6333],\n",
      "         [ 0.6776,  0.6970, -1.0699, -0.6333],\n",
      "         ...,\n",
      "         [-0.3806, -0.1967, -0.6744, -0.7778],\n",
      "         [-0.3863, -0.2022, -0.6744, -0.7833],\n",
      "         [-0.3902, -0.2105, -1.0699, -0.8333]]], dtype=torch.float64), tensor([[[1, 4, 4,  ..., 4, 1, 1]]])]\n",
      "[tensor([[[-0.7924, -0.8621,  0.1067,  0.8889],\n",
      "         [-0.8093, -0.8600, -0.0073,  0.9000],\n",
      "         [-0.8262, -0.8578,  0.0532,  0.8889],\n",
      "         ...,\n",
      "         [ 0.1233, -0.8289, -1.1012,  0.1611],\n",
      "         [ 0.1271, -0.8284, -1.1897,  0.1111],\n",
      "         [ 0.1304, -0.8277, -1.1268,  0.1444]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[ 1.0243, -0.8596, -1.1631,  0.6778],\n",
      "         [ 1.0230, -0.8561, -1.1412,  0.6889],\n",
      "         [ 1.0218, -0.8532, -1.2945,  0.7000],\n",
      "         ...,\n",
      "         [-0.6477, -3.7568,  1.3201, -0.4722],\n",
      "         [-0.6454, -3.7797,  1.3201, -0.4389],\n",
      "         [-0.6416, -3.8026,  1.3401, -0.4111]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[-0.9511, -0.8282, -1.2322, -0.0222],\n",
      "         [-0.9476, -0.8276, -1.2727,  0.0389],\n",
      "         [-0.9422, -0.8269, -1.0917,  0.0944],\n",
      "         ...,\n",
      "         [ 1.4298, -0.8021, -0.9630,  0.0389],\n",
      "         [ 1.4381, -0.8019, -0.9130,  0.0222],\n",
      "         [ 1.4470, -0.8015, -0.7963,  0.0333]]], dtype=torch.float64), tensor([[[1, 4, 4,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[-0.6061, -0.8358, -1.3212,  0.1333],\n",
      "         [-0.6026, -0.8353, -1.3839,  0.0833],\n",
      "         [-0.5976, -0.8353, -1.2613,  0.0833],\n",
      "         ...,\n",
      "         [-0.0672, -0.8618, -0.4847,  0.0056],\n",
      "         [-0.0568, -0.8635, -0.0732, -0.0833],\n",
      "         [-0.0441, -0.8668,  0.3710, -0.1278]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 4, 1, 1]]])]\n",
      "[tensor([[[-0.5720, -1.0452, -1.4961,  0.2000],\n",
      "         [-0.5706, -1.0450, -1.5486,  0.2056],\n",
      "         [-0.5683, -1.0448, -1.4536,  0.1056],\n",
      "         ...,\n",
      "         [ 1.5779, -0.8246, -0.4404, -0.7889],\n",
      "         [ 1.5689, -0.8262, -0.6706, -0.8667],\n",
      "         [ 1.5598, -0.8275, -0.6281, -0.8889]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 4, 1, 1]]])]\n",
      "[tensor([[[-1.0926, -0.8198, -1.3686,  0.0611],\n",
      "         [-1.0902, -0.8200, -1.2803,  0.0500],\n",
      "         [-1.0887, -0.8204, -1.3065, -0.0556],\n",
      "         ...,\n",
      "         [-0.0886, -0.8043,  0.4103, -0.3500],\n",
      "         [-0.0871, -0.8112,  0.2168, -0.4833],\n",
      "         [-0.0905, -0.8165, -0.2106, -0.6000]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 4, 4, 4]]])]\n",
      "[tensor([[[ 0.8135, -0.4073, -1.3929,  0.3278],\n",
      "         [ 0.8372, -0.2623, -1.4147,  0.3056],\n",
      "         [ 0.8610, -0.1204, -1.2842,  0.4000],\n",
      "         ...,\n",
      "         [ 1.1008, -0.2343, -1.4661,  0.1389],\n",
      "         [ 1.1013, -0.2339, -1.4661,  0.1444],\n",
      "         [ 1.1018, -0.2328, -1.4443,  0.1722]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 4, 4, 1]]])]\n",
      "[tensor([[[-0.5045, -0.8959, -1.3336,  0.0722],\n",
      "         [-0.5024, -0.8956, -1.4420,  0.0722],\n",
      "         [-0.5003, -0.8950, -1.3052,  0.1389],\n",
      "         ...,\n",
      "         [-1.2056, -0.8004,  0.4938, -0.2611],\n",
      "         [-1.1955, -0.8070,  0.6435, -0.3000],\n",
      "         [-1.1841, -0.8137,  0.7700, -0.2833]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 1, 1, 1]]])]\n",
      "[tensor([[[ 0.1226, -1.0013, -0.9876,  0.1667],\n",
      "         [ 0.1252, -1.0003, -1.3328,  0.1556],\n",
      "         [ 0.1278, -0.9991, -1.2969,  0.1611],\n",
      "         ...,\n",
      "         [-0.1849, -0.8772,  0.3713, -0.2889],\n",
      "         [-0.1790, -0.8839,  0.5066, -0.3000],\n",
      "         [-0.1723, -0.8904,  0.5342, -0.2778]]], dtype=torch.float64), tensor([[[4, 4, 4,  ..., 7, 7, 7]]])]\n",
      "[tensor([[[ 0.3790, -0.5101, -1.7803,  0.0389],\n",
      "         [-0.1900,  0.8822,  0.1684,  0.1611],\n",
      "         [-0.1718,  0.8871,  0.2485,  0.1833],\n",
      "         ...,\n",
      "         [-0.9690, -1.6392, -2.0836, -0.7111],\n",
      "         [-0.9687, -1.6394, -2.0836, -0.7111],\n",
      "         [-0.9684, -1.6396, -2.0836, -0.7111]]], dtype=torch.float64), tensor([[[4, 4, 1,  ..., 1, 1, 1]]])]\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
