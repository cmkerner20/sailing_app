{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "going through http://web.stanford.edu/class/cs224n/ and https://github.com/bentrevett/pytorch-pos-tagging/blob/master/1%20-%20BiLSTM%20for%20PoS%20Tagging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Using cached https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /Users/cmkerner/anaconda2/envs/py3/lib/python3.7/site-packages (from torchtext) (2.22.0)\n",
      "Collecting torch (from torchtext)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/6f/cdee668c94f5efb3745e9485765fd6b4918a855f7d36c0514ddf38daaddf/torch-1.5.0-cp37-none-macosx_10_9_x86_64.whl (80.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 80.5MB 437kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/cmkerner/anaconda2/envs/py3/lib/python3.7/site-packages (from torchtext) (1.15.4)\n",
      "Collecting tqdm (from torchtext)\n",
      "  Using cached https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /Users/cmkerner/anaconda2/envs/py3/lib/python3.7/site-packages (from torchtext) (1.11.0)\n",
      "Collecting sentencepiece (from torchtext)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/e3/2d755b55423787f438269a26d8bd9743698921fdcde748c6fb050b1c1b8c/sentencepiece-0.1.91-cp37-cp37m-macosx_10_6_x86_64.whl (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 4.7MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/cmkerner/anaconda2/envs/py3/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/cmkerner/anaconda2/envs/py3/lib/python3.7/site-packages (from requests->torchtext) (1.25.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/cmkerner/anaconda2/envs/py3/lib/python3.7/site-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cmkerner/anaconda2/envs/py3/lib/python3.7/site-packages (from requests->torchtext) (2018.10.15)\n",
      "Collecting future (from torch->torchtext)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz\n",
      "Building wheels for collected packages: future\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/cmkerner/Library/Caches/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "Successfully built future\n",
      "Installing collected packages: future, torch, tqdm, sentencepiece, torchtext\n",
      "Successfully installed future-0.18.2 sentencepiece-0.1.91 torch-1.5.0 torchtext-0.6.0 tqdm-4.46.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting random\n",
      "\u001b[31m  Could not find a version that satisfies the requirement random (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for random\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower = True)\n",
    "UD_TAGS = data.Field(unk_token = None)\n",
    "PTB_TAGS = data.Field(unk_token = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS), (\"ptbtags\", PTB_TAGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'UDPOS' has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-52f0d5cc0e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUDPOS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'UDPOS' has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "datasets.UDPOS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading en-ud-v2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 4.92MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['al',\n",
       "  '-',\n",
       "  'zaman',\n",
       "  ':',\n",
       "  'american',\n",
       "  'forces',\n",
       "  'killed',\n",
       "  'shaikh',\n",
       "  'abdullah',\n",
       "  'al',\n",
       "  '-',\n",
       "  'ani',\n",
       "  ',',\n",
       "  'the',\n",
       "  'preacher',\n",
       "  'at',\n",
       "  'the',\n",
       "  'mosque',\n",
       "  'in',\n",
       "  'the',\n",
       "  'town',\n",
       "  'of',\n",
       "  'qaim',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'syrian',\n",
       "  'border',\n",
       "  '.'],\n",
       " 'udtags': ['PROPN',\n",
       "  'PUNCT',\n",
       "  'PROPN',\n",
       "  'PUNCT',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'PROPN',\n",
       "  'PROPN',\n",
       "  'PROPN',\n",
       "  'PUNCT',\n",
       "  'PROPN',\n",
       "  'PUNCT',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'PROPN',\n",
       "  'PUNCT',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT'],\n",
       " 'ptbtags': ['NNP',\n",
       "  'HYPH',\n",
       "  'NNP',\n",
       "  ':',\n",
       "  'JJ',\n",
       "  'NNS',\n",
       "  'VBD',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'HYPH',\n",
       "  'NNP',\n",
       "  ',',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  ',',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  '.']}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.'], 'udtags': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], 'ptbtags': ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['udtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['ptbtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using UD tags - universal dependancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [07:45, 1.85MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:15<00:00, 25413.45it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "UD_TAGS.build_vocab(train_data)\n",
    "PTB_TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 8866\n",
      "Unique tokens in UD_TAG vocabulary: 18\n",
      "Unique tokens in PTB_TAG vocabulary: 51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in UD_TAG vocabulary: {len(UD_TAGS.vocab)}\")\n",
    "print(f\"Unique tokens in PTB_TAG vocabulary: {len(PTB_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 9076), ('.', 8640), (',', 7021), ('to', 5137), ('and', 5002), ('a', 3782), ('of', 3622), ('i', 3379), ('in', 3112), ('is', 2239), ('you', 2156), ('that', 2036), ('it', 1850), ('for', 1842), ('-', 1426), ('have', 1359), ('\"', 1296), ('on', 1273), ('was', 1244), ('with', 1216)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.datasets.sequence_tagging.UDPOS at 0x10bb11828>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout, \n",
    "                 pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers = n_layers, \n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout if n_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        #pass text through embedding layer\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pass embeddings into LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        #outputs holds the backward and forward hidden states in the final layer\n",
    "        #hidden and cell are the backward and forward hidden and cell states at the final time-step\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #we use our outputs to make a prediction of what the tag should be\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 32\n",
    "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = False\n",
    "DROPOUT = 0.25\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = BiLSTMPOSTagger(INPUT_DIM, \n",
    "                        EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT, \n",
    "                        PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMPOSTagger(\n",
       "  (embedding): Embedding(8866, 100, padding_idx=1)\n",
       "  (lstm): LSTM(100, 32, num_layers=2, dropout=0.25)\n",
       "  (fc): Linear(in_features=32, out_features=18, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 912,794 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8866, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.udtags\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        predictions = model(text)\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "        #tags = [sent len * batch size]\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.udtags\n",
    "            \n",
    "            predictions = model(text)\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 2.564 | Train Acc: 18.35%\n",
      "\t Val. Loss: 2.220 |  Val. Acc: 36.70%\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 1.791 | Train Acc: 48.57%\n",
      "\t Val. Loss: 1.409 |  Val. Acc: 57.35%\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 1.197 | Train Acc: 65.52%\n",
      "\t Val. Loss: 0.991 |  Val. Acc: 74.20%\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.875 | Train Acc: 76.51%\n",
      "\t Val. Loss: 0.762 |  Val. Acc: 81.63%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.687 | Train Acc: 82.32%\n",
      "\t Val. Loss: 0.647 |  Val. Acc: 83.37%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.580 | Train Acc: 84.76%\n",
      "\t Val. Loss: 0.586 |  Val. Acc: 83.58%\n",
      "Epoch: 07 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.519 | Train Acc: 86.15%\n",
      "\t Val. Loss: 0.554 |  Val. Acc: 84.17%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.477 | Train Acc: 86.95%\n",
      "\t Val. Loss: 0.532 |  Val. Acc: 84.30%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.448 | Train Acc: 87.54%\n",
      "\t Val. Loss: 0.520 |  Val. Acc: 84.58%\n",
      "Epoch: 10 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.425 | Train Acc: 88.06%\n",
      "\t Val. Loss: 0.505 |  Val. Acc: 84.86%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
