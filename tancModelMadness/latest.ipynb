{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/Users/tancredicp/Desktop/sailing_app/data/ML Training Resources/'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "TAGS = data.Field(unk_token = None)\n",
    "TAGS.build_vocab(['0','S', 'C','G','T','B','D', 'A'])\n",
    "\n",
    "Data = []\n",
    "for filename in all_files:\n",
    "    temporary_dict = {}\n",
    "\n",
    "    dfSpecific = pd.read_csv(filename, index_col=None, header=0)\n",
    "    dfSpecific.fillna(0, ianplace= True)\n",
    "    \n",
    "    dfSpecificY = dfSpecific['tag']\n",
    "    temporary_dict['tags'] = TAGS.numericalize((np.array(dfSpecificY)))\n",
    "    \n",
    "\n",
    "    dfSpecificX = dfSpecific.drop(columns=['tag', 'tag_name', 'boat_class', 'time'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    columnsBeingStandardize = ['lat', 'lon', 'sog', 'heel', 'clew_load','pitch']\n",
    "    dfSpecificX[columnsBeingStandardize] = scaler.fit_transform(dfSpecificX[columnsBeingStandardize])\n",
    "    \n",
    "    \n",
    "    array1 = np.array(dfSpecificX[['lat', 'lon', 'sog', 'cog']])\n",
    "    \n",
    "    temp = torch.from_numpy(array1)\n",
    "    \n",
    "    temporary_dict['track'] = temp\n",
    "    \n",
    "    Data.append(temporary_dict)\n",
    "    del(temporary_dict)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Dataset \n",
    "from torch.utils.data import Dataset\n",
    "class SailingData(Dataset):\n",
    "    def __init__ (self, tracks):\n",
    "        self.samples = []\n",
    "        \n",
    "        for track in tracks:\n",
    "            self.samples.append((track['track'], track['tags']))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "            return(self.samples[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train iterator\n",
    "BATCH_SIZE = 1#the automatic batch size is 1\n",
    "DatasetSailing= SailingData(Data)\n",
    "train_iterator = torch.utils.data.DataLoader(DatasetSailing, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5169, -0.5162,  1.3716, -0.3000],\n",
       "         [ 0.5262, -0.5372,  1.5119, -0.3111],\n",
       "         [ 0.5362, -0.5570,  1.4558, -0.2722],\n",
       "         ...,\n",
       "         [ 0.9956, -1.3453, -1.1912, -0.3667],\n",
       "         [ 0.9956, -1.3475, -1.1459, -0.4167],\n",
       "         [ 0.9958, -1.3498, -1.1697, -0.4389]], dtype=torch.float64),\n",
       " tensor([[7, 7, 7,  ..., 4, 4, 4]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetSailing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size = 4, hidden_size = 32, num_layers = 2, dropout = 0.5)\n",
    "        self.fc1 = nn.Linear(32, 120)\n",
    "        self.fc2 = nn.Linear(120,9)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.unsqueeze(0)\n",
    "        x, _ = self.lstm1(x)\n",
    "#         print(x.shape)\n",
    "        x = F.dropout(x, p = 0.9)\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net = net.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy_score(o_lst, l_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  1 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  2 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  3 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  4 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  5 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  6 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  7 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  8 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  9 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  10 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  11 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  12 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  13 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  14 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  15 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  16 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  17 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  18 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  19 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  20 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  21 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  22 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  23 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  24 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  25 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  26 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  27 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  28 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  29 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  30 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  31 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  32 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  33 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  34 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  35 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  36 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  37 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  38 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  39 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  40 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  41 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  42 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  43 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  44 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  45 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  46 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  47 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  48 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  49 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  50 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  51 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  52 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  53 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  54 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  55 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  56 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  57 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  58 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  59 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  60 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  61 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  62 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  63 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  64 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  65 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  66 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  67 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  68 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  69 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  70 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  71 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  72 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  73 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  74 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  75 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  76 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  77 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  78 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  79 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  80 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  81 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  82 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  83 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  84 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  85 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  86 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  87 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  88 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  89 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  90 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  91 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  92 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  93 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  94 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  95 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  96 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  97 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  98 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Epoch:  99 Loss:  7896.825130945925 Accuracy:  0.029771841958820256\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    o_lst = []\n",
    "    l_lst = []\n",
    "    for i, data in enumerate(train_iterator, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        #WHAT DOES THIS DO \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         print(labels.shape)\n",
    "        for data_point, lab in zip(inputs[0], labels[0][0]):\n",
    "            outputs = net(data_point)\n",
    "            lab  = lab.unsqueeze(0)\n",
    "            outputs = outputs.squeeze(0)\n",
    "#             print('outputs', outputs.shape, 'lab', lab.shape)\n",
    "            loss = criterion(outputs, lab)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        \n",
    "        \n",
    "            o_lst.append((outputs.argmax().item()))\n",
    "            l_lst.append(lab.item())\n",
    "       \n",
    "#             break\n",
    "\n",
    "       \n",
    "    \n",
    "    accuracy = accuracy_score(o_lst, l_lst)\n",
    "    print(\"Epoch: \", epoch, \"Loss: \",running_loss, \"Accuracy: \" , accuracy)\n",
    "  \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i, data in enumerate(train_iterator, 0):\n",
    "    inputs, labels = data\n",
    "    o = net(inputs)\n",
    "    lst.append(o.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4, grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inti.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAGS.tokenize('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.field.Field at 0x128227150>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split() missing 1 required positional argument: 'split_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-9439c47d7559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/sailing_env/sailing/lib/python3.7/site-packages/torchtext/data/utils.py\u001b[0m in \u001b[0;36m_split_tokenizer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_split_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: split() missing 1 required positional argument: 'split_size'"
     ]
    }
   ],
   "source": [
    "TAGS.tokenize(torch.t[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 7]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAGS.numericalize(['A', 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
